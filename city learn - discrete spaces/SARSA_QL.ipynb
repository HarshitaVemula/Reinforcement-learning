{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citylearn import  CityLearn, building_loader, auto_size\n",
    "from energy_models import HeatPump, EnergyStorage, Building\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "np.random.seed(3)\n",
    "\n",
    "import ray \n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use only one building for SINGLE AGENT environment, unmark multiple building IDs to simulate MULTI-AGENT environment. In the multi-agent environment\n",
    "#the reward of each agent depend partially on the actions of the other agents or buildings (see reward_function.py)\n",
    "building_ids = [8]#, 5, 9, 16, 21, 26, 33, 36, 49, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.00000000e-01 -2.00000000e-01 -1.00000000e-01  5.55111512e-17\n",
      "  1.00000000e-01  2.00000000e-01  3.00000000e-01  4.00000000e-01]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Building the RL environment with heating and cooling loads and weather files\n",
    "CityLearn\n",
    "    Weather file\n",
    "    Buildings\n",
    "        File with heating and cooling demands\n",
    "        CoolingDevices (HeatPump)\n",
    "        CoolingStorages (EnergyStorage)\n",
    "'''\n",
    "\n",
    "data_folder = Path(\"data/\")\n",
    "\n",
    "demand_file = data_folder / \"AustinResidential_TH.csv\"\n",
    "weather_file = data_folder / 'Austin_Airp_TX-hour.csv'\n",
    "\n",
    "heat_pump, heat_tank, cooling_tank = {}, {}, {}\n",
    "\n",
    "#Ref: Assessment of energy efficiency in electric storage water heaters (2008 Energy and Buildings)\n",
    "loss_factor = 0.19/24\n",
    "buildings = []\n",
    "for uid in building_ids:\n",
    "    heat_pump[uid] = HeatPump(nominal_power = 9e12, eta_tech = 0.22, t_target_heating = 45, t_target_cooling = 10)\n",
    "    heat_tank[uid] = EnergyStorage(capacity = 9e12, loss_coeff = loss_factor)\n",
    "    cooling_tank[uid] = EnergyStorage(capacity = 9e12, loss_coeff = loss_factor)\n",
    "    buildings.append(Building(uid, heating_storage = heat_tank[uid], cooling_storage = cooling_tank[uid], heating_device = heat_pump[uid], cooling_device = heat_pump[uid]))\n",
    "    buildings[-1].state_space(np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1, 40.0, 1.001]), np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 17.0, -0.001]))\n",
    "    buildings[-1].action_space(np.array([0.5]), np.array([-0.3]))\n",
    "    \n",
    "building_loader(demand_file, weather_file, buildings)  \n",
    "auto_size(buildings, t_target_heating = 45, t_target_cooling = 10)\n",
    "\n",
    "env = CityLearn(demand_file, weather_file, buildings = buildings, time_resolution = 1, simulation_period = (3500,6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward_function import reward_function\n",
    "observations_space, actions_space = [],[]\n",
    "for building in buildings:\n",
    "    observations_space.append(building.observation_spaces)\n",
    "    actions_space.append(building.action_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward_function import reward_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.9\n",
    "w=np.ones(24+8)\n",
    "\n",
    "def generate_state_action_matrix(state,action_shape):\n",
    "    ns=len(state)\n",
    "    x_s_a=np.zeros((action_shape,ns+action_shape))\n",
    "    for i in range(action_shape):\n",
    "        l=np.zeros(action_shape)\n",
    "        l[i]=1\n",
    "        x_s_a[i,:]=np.concatenate([np.array(state),l])\n",
    "    return(x_s_a)\n",
    "    \n",
    "def get_q_values(x_s_a,w):\n",
    "    na=x_s_a.shape[0]\n",
    "    ns_na=x_s_a.shape[1]\n",
    "    q_s_a=np.zeros(na)\n",
    "    for i in range(na):\n",
    "        #print(w.reshape(1,32).shape)\n",
    "        #print(x_s_a[0,:].reshape(32,1).shape)\n",
    "        q_s_a[i]=np.matmul(w.reshape(1,ns_na),x_s_a[i,:].reshape(ns_na,1))\n",
    "        #print(q_s_a[i])\n",
    "    return(q_s_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.00000000e-01, -2.00000000e-01, -1.00000000e-01,  5.55111512e-17,\n",
       "        1.00000000e-01,  2.00000000e-01,  3.00000000e-01,  4.00000000e-01])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space=np.arange(-0.3,0.5,0.1)\n",
    "action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.45633242157078\n",
      "207.79708014301963\n",
      "212.91057209964603\n",
      "215.87820965597064\n",
      "208.76994143248322\n",
      "209.58828467767987\n",
      "209.81606503279212\n",
      "209.1824008933386\n",
      "212.85672561944767\n",
      "211.93615806702576\n",
      "206.58280187793093\n",
      "214.453297283236\n",
      "209.3439791175629\n",
      "213.2629431353172\n",
      "210.7669777213256\n",
      "214.19528807366063\n",
      "209.66856026299118\n",
      "211.043631403325\n",
      "211.95450445279639\n",
      "207.68568509317348\n",
      "207.6896114752634\n",
      "211.71039069141568\n",
      "208.7884613345101\n",
      "213.40713102300717\n",
      "210.68526247574806\n",
      "213.47169311329355\n",
      "211.0302076925484\n",
      "214.07172795661333\n",
      "211.3828654175321\n",
      "211.8865258929652\n",
      "209.9543186365555\n",
      "210.6980112989772\n",
      "212.07330482066237\n",
      "213.3428237207736\n",
      "206.5225129033473\n",
      "210.50196558405713\n",
      "212.9327015333381\n",
      "210.55848228730963\n",
      "209.15268610190793\n",
      "212.6062453858052\n",
      "212.40819617232222\n",
      "210.38517969933645\n",
      "211.09370565000813\n",
      "213.50970185771033\n",
      "209.90619850002528\n",
      "212.0414742040319\n",
      "212.90959785587717\n",
      "214.64663938882256\n",
      "212.68493893342037\n",
      "213.75136350809328\n",
      "209.5415986646015\n",
      "212.0320942128574\n",
      "210.84236534610437\n",
      "209.88723223765697\n",
      "215.84077833806376\n",
      "207.49092587285654\n",
      "209.2061388371663\n",
      "209.35536159221297\n",
      "213.87948187819612\n",
      "212.39600883937524\n",
      "210.2783639123882\n",
      "209.34026419734394\n",
      "209.20108478558652\n",
      "209.89434111855778\n",
      "208.86942454202685\n",
      "207.1688352569144\n",
      "208.38190036398106\n",
      "206.47869105557118\n",
      "213.5793738232556\n",
      "214.3167127613171\n",
      "211.84189371570451\n",
      "210.56994493832488\n",
      "207.56853201001948\n",
      "210.1296310312776\n",
      "213.3346757062903\n",
      "213.59094908385435\n",
      "215.04708872566667\n",
      "211.07327259278168\n",
      "209.65121682688775\n",
      "211.187415466156\n",
      "212.4721275252332\n",
      "211.86107222352408\n",
      "212.22058764133806\n",
      "210.1616832206642\n",
      "214.83348770331406\n",
      "213.71345639093545\n",
      "211.68813400247046\n",
      "211.06527762369134\n",
      "214.6903718247315\n",
      "211.98540826690203\n",
      "211.66229796414368\n",
      "212.27217242185924\n",
      "209.244595997508\n",
      "213.51454340019214\n",
      "209.2322186313418\n",
      "211.12359700516254\n",
      "212.2462373497054\n",
      "211.67000867962398\n",
      "207.65785210924193\n",
      "214.00555290940235\n"
     ]
    }
   ],
   "source": [
    "#on policy sarsa\n",
    "#on policy sarsa with epsilon greedy much worse than greedy\n",
    "cost, cum_reward = {}, {}\n",
    "gamma=0.9\n",
    "alpha=0.1\n",
    "na=8\n",
    "for ep in range(100):\n",
    "    q=[]\n",
    "    states=[]\n",
    "    state = env.reset()\n",
    "    state=state[0][:24]\n",
    "    states.append(state)\n",
    "    done = False\n",
    "    \n",
    "    \n",
    "    x_s_a=generate_state_action_matrix(state,8)\n",
    "    q_s_a_s=get_q_values(x_s_a,w)\n",
    "    action=action_space[np.argmax(q_s_a_s)]\n",
    "    x=x_s_a[np.argmax(q_s_a_s)]\n",
    "    q.append(np.max(q_s_a_s))\n",
    "    while not done:\n",
    "        next_state, reward, done, _ = env.step([[action]])\n",
    "        reward = reward_function(reward)[0] \n",
    "        #print('rea',reward)\n",
    "        state = next_state[0][:24]\n",
    "        \n",
    "        x_s_dash_a=generate_state_action_matrix(state,8)\n",
    "        q_s_dash_a_s=get_q_values(x_s_dash_a,w)\n",
    "        \n",
    "        epsilon=np.random.rand(1)\n",
    "        if epsilon<0.7:\n",
    "            action_dash=action_space[np.argmax(q_s_dash_a_s)]\n",
    "            q_s_dash=np.max(q_s_dash_a_s)\n",
    "            x_=x_s_dash_a[np.argmax(q_s_dash_a_s)]\n",
    "            \n",
    "        else:\n",
    "            ac=np.random.choice(na)\n",
    "            action_dash=action_space[ac]\n",
    "            q_s_dash=q_s_dash_a_s[ac]\n",
    "            x_=x_s_dash_a[ac]\n",
    "        #print(np.matmul(w,x))\n",
    "        #print(np.matmul(w,x_s_dash_a[np.argmax(q_s_dash_a_s)]))\n",
    "        q_s=q[-1]\n",
    "        w=w+alpha*(reward+gamma*q_s_dash-q_s)*(gamma*x_-x)\n",
    "        \n",
    "        q.append(q_s_dash)\n",
    "        \n",
    "        action=action_dash\n",
    "        x=x_\n",
    "    cost[ep] = env.cost()\n",
    "    print(cost[ep])\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.40900847061246\n",
      "180.53393503856896\n",
      "180.66307259918216\n",
      "180.52080049387337\n",
      "180.49528783022978\n",
      "180.47274440159893\n",
      "180.434599219371\n",
      "180.5257305804471\n",
      "180.52994307696972\n",
      "180.62521659615845\n",
      "180.52080049387337\n",
      "180.49528783022978\n",
      "180.47274440159893\n",
      "180.434599219371\n",
      "180.5257305804471\n",
      "180.52994307696972\n",
      "180.62521659615845\n",
      "180.52080049387337\n",
      "180.49528783022978\n",
      "180.47274440159893\n",
      "180.434599219371\n",
      "180.5257305804471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: RuntimeWarning: overflow encountered in double_scalars\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.3170853281487\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n",
      "180.25737295269303\n"
     ]
    }
   ],
   "source": [
    "#sarsa greedy\n",
    "cost, cum_reward = {}, {}\n",
    "gamma=0.9\n",
    "alpha=0.1\n",
    "na=8\n",
    "w=np.ones(32)\n",
    "for ep in range(100):\n",
    "    q=[]\n",
    "    states=[]\n",
    "    state = env.reset()\n",
    "    state=state[0][:24]\n",
    "    states.append(state)\n",
    "    done = False\n",
    "    \n",
    "    \n",
    "    x_s_a=generate_state_action_matrix(state,8)\n",
    "    q_s_a_s=get_q_values(x_s_a,w)\n",
    "    action=action_space[np.argmax(q_s_a_s)]\n",
    "    x=x_s_a[np.argmax(q_s_a_s)]\n",
    "    q.append(np.max(q_s_a_s))\n",
    "    while not done:\n",
    "        next_state, reward, done, _ = env.step([[action]])\n",
    "        reward = reward_function(reward)[0] \n",
    "        #print('rea',reward)\n",
    "        state = next_state[0][:24]\n",
    "        \n",
    "        x_s_dash_a=generate_state_action_matrix(state,8)\n",
    "        q_s_dash_a_s=get_q_values(x_s_dash_a,w)\n",
    "        \n",
    "        epsilon=np.random.rand(1)\n",
    "        #if epsilon<0.7:\n",
    "        action_dash=action_space[np.argmax(q_s_dash_a_s)]\n",
    "        q_s_dash=np.max(q_s_dash_a_s)\n",
    "        x_=x_s_dash_a[np.argmax(q_s_dash_a_s)]\n",
    "            \n",
    "#         else:\n",
    "#             ac=np.random.choice(na)\n",
    "#             action_dash=action_space[ac]\n",
    "#             q_s_dash=q_s_dash_a_s[ac]\n",
    "#             x_=x_s_dash_a[ac]\n",
    "        #print(np.matmul(w,x))\n",
    "        #print(np.matmul(w,x_s_dash_a[np.argmax(q_s_dash_a_s)]))\n",
    "        q_s=q[-1]\n",
    "        w=w+alpha*(reward+gamma*q_s_dash-q_s)*(gamma*x_-x)\n",
    "        \n",
    "        q.append(q_s_dash)\n",
    "        \n",
    "        action=action_dash\n",
    "        x=x_\n",
    "    cost[ep] = env.cost()\n",
    "    print(cost[ep])\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.7785537611777\n",
      "195.87893517418928\n",
      "197.31352797014839\n",
      "196.25813051958207\n",
      "194.84779475397622\n",
      "195.47935961556\n",
      "195.41635263119434\n",
      "195.02502920559255\n",
      "195.05472343671522\n",
      "196.06723487103153\n",
      "196.60921795038834\n",
      "197.0381282875192\n",
      "195.70548139389857\n",
      "194.91254911564752\n",
      "195.37059015725123\n",
      "195.2383221258765\n",
      "195.50643750011403\n",
      "196.08142165924005\n",
      "194.36577593074261\n",
      "195.702408206766\n",
      "196.1813634084208\n",
      "195.10260042612197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: RuntimeWarning: overflow encountered in double_scalars\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204.4504002066826\n",
      "212.21939707456477\n",
      "206.05481775015213\n",
      "210.26302373255905\n",
      "210.8358306629208\n",
      "210.1672014531316\n",
      "210.27405438587272\n",
      "214.1022604052116\n",
      "214.82426070308873\n",
      "211.6755645439997\n",
      "212.8408300352563\n",
      "211.4525275681009\n",
      "214.7246346057107\n",
      "212.6084896541909\n",
      "214.53243791277663\n",
      "210.5907491950985\n",
      "213.13451297009874\n",
      "211.61213750362012\n",
      "212.26357596786434\n",
      "212.31616898825652\n",
      "211.03088113231914\n",
      "210.27595003849373\n",
      "211.080874502206\n",
      "210.3424342078972\n",
      "210.4376143255399\n",
      "213.20713861923196\n",
      "210.32883585368074\n",
      "211.19812658735157\n",
      "213.60847667326493\n",
      "214.83895312158296\n",
      "209.79274954147462\n",
      "212.18296447750265\n",
      "212.2783337516782\n",
      "214.83981473012022\n",
      "209.6105243787246\n",
      "209.77321862969552\n",
      "208.0574583606622\n",
      "216.65203808574105\n",
      "213.57866693705733\n",
      "212.55831316553153\n",
      "211.96614624194987\n",
      "206.57469309570416\n",
      "211.62979072025746\n",
      "209.61803635310238\n",
      "209.3438867415649\n",
      "213.35301851933067\n",
      "211.4229131778351\n",
      "209.05881392804207\n",
      "212.39510880384825\n",
      "208.1255381894592\n",
      "210.30904634521949\n",
      "212.6404526782735\n",
      "213.31702230508157\n",
      "213.45946171894104\n",
      "211.1174247423507\n",
      "212.251345340237\n",
      "211.21090251805458\n",
      "213.62280375033876\n",
      "215.1272500361972\n",
      "209.36373001072093\n",
      "211.7638438558465\n",
      "209.66941831033475\n",
      "213.03875839628657\n",
      "212.25480668472434\n",
      "213.00427413615384\n",
      "210.21675865245035\n",
      "211.28122963951415\n",
      "214.48335374588984\n",
      "210.07614537052507\n",
      "213.0024858614682\n",
      "211.2298864675363\n",
      "211.5202789360637\n",
      "211.52338263459464\n",
      "209.98180111976959\n",
      "213.44405524965305\n",
      "212.37198738548312\n",
      "211.73374297250456\n",
      "207.57724625300617\n"
     ]
    }
   ],
   "source": [
    "#Qlearning\n",
    "cost, cum_reward = {}, {}\n",
    "gamma=0.9\n",
    "alpha=0.1\n",
    "na=8\n",
    "for ep in range(100):\n",
    "    q=[]\n",
    "    states=[]\n",
    "    state = env.reset()\n",
    "    state=state[0][:24]\n",
    "    states.append(state)\n",
    "    done = False\n",
    "    \n",
    "    \n",
    "    x_s_a=generate_state_action_matrix(state,8)\n",
    "    q_s_a_s=get_q_values(x_s_a,w)\n",
    "    action=action_space[np.argmax(q_s_a_s)]\n",
    "    x=x_s_a[np.argmax(q_s_a_s)]\n",
    "    q.append(np.max(q_s_a_s))\n",
    "    while not done:\n",
    "        next_state, reward, done, _ = env.step([[action]])\n",
    "        reward = reward_function(reward)[0] \n",
    "        state = next_state[0][:24]\n",
    "        \n",
    "        x_s_dash_a=generate_state_action_matrix(state,8)\n",
    "        q_s_dash_a_s=get_q_values(x_s_dash_a,w)\n",
    "        \n",
    "        epsilon=np.random.rand(1)\n",
    "        if epsilon<0.7:\n",
    "            action_dash=action_space[np.argmax(q_s_dash_a_s)]\n",
    "            \n",
    "        else:\n",
    "            ac=np.random.choice(na)\n",
    "            action_dash=action_space[ac]\n",
    "        p=np.argmax(q_s_dash_a_s)    \n",
    "        q_s_dash=np.max(q_s_dash_a_s)\n",
    "        x_=x_s_dash_a[p]\n",
    "        #print(np.matmul(w,x))\n",
    "        #print(np.matmul(w,x_s_dash_a[np.argmax(q_s_dash_a_s)]))\n",
    "        q_s=q[-1]\n",
    "        w=w+alpha*(reward+gamma*q_s_dash-q_s)*(gamma*x_-x)\n",
    "        \n",
    "        q.append(q_s_dash)\n",
    "        \n",
    "        action=action_dash\n",
    "        x=x_\n",
    "    cost[ep] = env.cost()\n",
    "    print(cost[ep])\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
